program: train.py
name: sweep1
method: random  # Options: "bayes", "grid", etc.
metric:
  name: avg_reward  # Metric to optimize
  goal: maximize

parameters:
  learning_rate:
    values: [0.0001, 0.001, 0.005, 0.01]
  batch_size:
    values: [8, 16, 32, 64]
  eps_end:
    values: [0.01, 0.05, 0.1]
  discount_factor:
    value: 0.99
  replay_buffer_size:
    value: 100000
  update_freq:
    value: 100
  eps_start:
    value: 0.5
  schedule_duration:
    value: 15000
  num_episodes:
    value: 1000
  is_double_dqn:
    values: [True, False]
  is_noisy_nets:
    values: [True, False]
  is_distributional:
    value: False
  std_init:
    values: [0.1, 0.2, 0.3, 0.4, 0.5]
  num_atoms:
    values: [5, 21, 51]
  is_dueling_dqn:
    values: [ true ]  # Toggle Dueling Networks
  is_multi_step:
    values: [ false ]   # Toggle Multi-Step Learning
  n_step:
    values: [1, 3, 5]  # Number of steps for Multi-Step Learning

early_terminate:
  type: hyperband # Aggressively terminate poorly performing runs
  min_iter: 5 # Minimum episodes before termination
  eta: 2 # Fraction of runs to discard at each stage
  s: 2 # Number of brackets for Hyperband
